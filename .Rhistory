?curl
jsonData <- fromJSON("http://openexchangerates.org/api/latest.json?app_id=b399b7cb3faf4d3f951358d32b0d34f2")
head(fromJSON)
?fromJSON
download.file("http://pdf.keysnews.com/frontpage.pdf",destfile="./test.pdf", method="curl")
download.file("http://pdf.keysnews.com/frontpage.pdf",destfile="./test.pdf")
jsonData <- fromJSON("http://openexchangerates.org/api/latest.json?app_id=b399b7cb3faf4d3f951358d32b0d34f2",method="curl")
?ping
??ping
download.file("http://openexchangerates.org/api/latest.json?app_id=b399b7cb3faf4d3f951358d32b0d34f2",destfile="./test.json")
dir()
testJSON <- fromJSON("test.json")
View(testJSON)
?download.file
jsonData <- fromJSON("http://openexchangerates.org/api/latest.json?app_id=b399b7cb3faf4d3f951358d32b0d34f2",method="wget")
read.table("http://openexchangerates.org/api/latest.json?app_id=b399b7cb3faf4d3f951358d32b0d34f2")
readLines(""http://openexchangerates.org/api/latest.json?app_id=b399b7cb3faf4d3f951358d32b0d34f2"")
readLines("http://openexchangerates.org/api/latest.json?app_id=b399b7cb3faf4d3f951358d32b0d34f2")
testJSON <- readLines("http://openexchangerates.org/api/latest.json?app_id=b399b7cb3faf4d3f951358d32b0d34f2")
View(testJSON)
readJSON(testJSON)
?scan
scan(file="http://openexchangerates.org/api/latest.json?app_id=b399b7cb3faf4d3f951358d32b0d34f2")
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/chord diagram.R', echo=TRUE)
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/chord diagram.R', echo=TRUE)
install.packages("circlize")
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/chord diagram.R', echo=TRUE)
insta..packages("circlize")
install.packages("circlize")
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/chord diagram.R', echo=TRUE)
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/chord diagram.R', echo=TRUE)
ping()
?ping
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/chord diagram.R', echo=TRUE)
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/Countriesdistance.R', echo=TRUE)
lesDist <- rbind_all(mget(lesDist))
lesDist <- lapply(indicePays[-length(indicePays)], lesDistancesUnPays)
lesDist <- rbind_all(lesDist)
View(lesDist)
head(lesDist)
lesDist <- rbind_list(lesDist)
# http://editerna.free.fr/wp/?p=199
# load(url("http://editerna.free.fr/R/Blog/Cartes/countries_distances.RData"))
library(maps)
library(geosphere)
library(dplyr)
world.map <- map("world", fill = TRUE)
indicePays <- seq(1,length(world.map$names))[-grep(":", world.map$names)]
# https://stat.ethz.ch/pipermail/r-help/2010-April/237031.html
splitNA <- function(x){
idx <- 1 + cumsum(is.na(x))
not.na <- !is.na(x)
split(x[not.na], idx[not.na])
}
# Coordinates of every country
lesCoordsX <- splitNA(world.map$x)
lesCoordsY <- splitNA(world.map$y)
lesDistancesUnPays <- function(unIndicePays){
# Borders coordinates for current country
coordsPays <- data.frame(long = lesCoordsX[[unIndicePays]], lat = lesCoordsY[[unIndicePays]])
# Indexes of countries except the current one
# and the one for which the computation has already been done
lesIndicesAutresPays <- indicePays[indicePays > unIndicePays]
distancePoint <- function(unPoint){
unPoint.m <- matrix(unPoint, ncol = 2)
# We need to compute distances between unPoint and every border points of every other countries
# it is given by lesIndicesAutresPays
distancePointPays <- function(unIndicePays2){
coordsPays2 <- matrix(cbind(long = lesCoordsX[[unIndicePays2]], lat = lesCoordsY[[unIndicePays2]]), ncol = 2)
lesDistPointPays2 <- spDists(x=coordsPays2, y=matrix(unPoint, ncol=2), longlat=TRUE)
return(min(lesDistPointPays2)) # shortest distance between unPoint and country which index is unIndicePays2
}
lesDistPointPays2 <- lapply(lesIndicesAutresPays, distancePointPays)
res <- unlist(lesDistPointPays2)
return(res)
}
distancesPays <- apply(coordsPays, 1, distancePoint)
# Shortest distances between unPoint and every other country
if(!is.matrix(distancesPays)){
# For the last country on the list
plusCourtesDistances <- min(distancesPays)
}else{
plusCourtesDistances <- apply(distancesPays, 1, min)
}
resul <- cbind(pays1 = rep(unIndicePays, length(plusCourtesDistances)),pays2 = lesIndicesAutresPays, dist = plusCourtesDistances)
return(resul)
}
# We don't need distances for the last country (they have all been computed)
lesDist <- lapply(indicePays[-length(indicePays)], lesDistancesUnPays)
lesDist <- rbind_list(lesDist)
# We need to recover distances for each couple
lesDist$ID <- paste(sprintf("%04d", lesDist$pays1), sprintf("%04d", lesDist$pays2), sep = "")
lesDist2 <- data.frame(cbind(pays1 = rep(indicePays, each = length(indicePays)),
pays2 = rep(indicePays, length(indicePays))))
lesDist2  <-  lesDist2[-which(lesDist2$pays1 == lesDist2$pays2),]
lesDist2$ID <- paste(sprintf("%04d", lesDist2$pays1), sprintf("%04d", lesDist2$pays2), sep = "")
lesDist2$ID2 <- paste(sprintf("%04d", lesDist2$pays2), sprintf("%04d", lesDist2$pays1), sep = "")
lesDist2$match <- match(lesDist2$ID, lesDist$ID)
lesDist2[is.na(lesDist2$match),"match"] <- match(lesDist2$ID2[is.na(lesDist2$match)], lesDist$ID)
lesDist2$dist <- lesDist[lesDist2$match, "dist"]
lesDist2 <- lesDist2[,c("pays1", "pays2", "dist")]
lesDist <- lesDist2
rm(lesDist2)
# Let's add countries names
lesDist$pays1 <- world.map$names[lesDist$pays1]
lesDist$pays2 <- world.map$names[lesDist$pays2]
source('~/.active-rstudio-document', echo=TRUE)
lesDist <- lapply(indicePays[-length(indicePays)], lesDistancesUnPays)
install.packages("rJava")
install.packages("randomForest")
install.packages("randomForest")
install.packages("quantmod")
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/Countriesdistance.R', echo=TRUE)
lesDist[lesDist$dist == 0,]
distances <- lesDist
bordercountries <- lesDist[lesDist$dist == 0,]
View(bordercountries)
View(bordercountries)
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/Countriesdistance.R', echo=TRUE)
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/chord diagram.R', echo=TRUE)
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/chord diagram.R', echo=TRUE)
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/chord diagram.R', echo=TRUE)
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/chord diagram.R', echo=TRUE)
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/Countriesdistance.R', echo=TRUE)
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/chord diagram.R', echo=TRUE)
View(lesDist)
View(bordercountries)
load(url("http://editerna.free.fr/R/Blog/Cartes/countries_distances.RData"))
View(lesDist)
?
load
?url
install.packages("countrycode")
?countrycode
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/chord diagram.R', echo=TRUE)
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/chord diagram.R', echo=TRUE)
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/chord diagram.R', echo=TRUE)
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/chord diagram.R', echo=TRUE)
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/chord diagram.R', echo=TRUE)
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/Countriesdistance.R', echo=TRUE)
install.packages("cshapes")
source('~/.active-rstudio-document', echo=TRUE)
?plotly
source('~/R/test/plotlyapi.R', echo=TRUE)
?py
py
?plotly
source('~/R/test/plotlyapi.R', echo=TRUE)
source('~/R/test/plotlyapi.R', echo=TRUE)
source('~/R/test/plotlyapi.R', echo=TRUE)
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/chord diagram.R', echo=TRUE)
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/chord diagram.R', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
install.packages("KernSmooth")
library(KernSmooth)
?factor
library(lattice)
?xyplot
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
print(p)
?print.trellis
?splom
?trellis.par.set
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
library(ggplot2)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
?ggplot
qplot(votes, rating, data = movies)
head(movies)
str(movies)
qplot(votes, rating, data = movies) + geom_smooth()
install.packages(c("BH", "crayon", "curl"))
install.packages(c("devtools", "evaluate", "formatR", "gdata", "gtools", "highr"))
install.packages(c("devtools", "evaluate", "formatR", "gdata", "gtools", "highr", "jsonlite", "knitr", "manipulate", "maptools", "markdown", "plyr", "Rcpp", "RCurl", "rmarkdown", "roxygen2", "sp", "stringr"))
install.packages(c("BH", "codetools", "curl", "devtools", "evaluate", "formatR", "gdata", "gtools", "highr", "jsonlite", "knitr", "lattice", "manipulate", "markdown", "MASS", "Matrix", "mgcv", "plyr", "Rcpp", "RCurl", "rmarkdown", "roxygen2", "sp", "stringr"), lib="C:/Program Files/R/R-3.1.3/library")
# Print to png
## PLOT1
## Question: Have total emissions from PM2.5 decreased in the United States from 1999 to 2008?
## Make a plot showing the total PM2.5 emission from all sources for each of the years 1999, 2002, 2005, and 2008.
## Plotting system: base
# Load data
if(!exists("NEI")) NEI <- readRDS("summarySCC_PM25.rds") # slowwww
if(!exists("SCC")) SCC <- readRDS("Source_Classification_Code.rds")
# ETL
aggregated <- aggregate(Emissions ~ year,data=NEI,FUN=sum)
# Print to screen
barplot(height=aggregated$Emissions/10^6,names.arg=aggregated$year,
xlab="year",ylab="Total PM2.5 Emissions (M Tons)",main="PM2.5 Emissions (M Tons) for Total US")
# Print to png
png("plot1.png", height=480, width=480)
barplot(height=aggregated$Emissions/10^6,names.arg=aggregated$year,
xlab="year",ylab="Total PM2.5 Emissions (M Tons)",main="PM2.5 Emissions (M Tons) for Total US")
dev.off()
## PLOT2
## Question:Have total emissions from PM2.5 decreased in the Baltimore City, Maryland (fips == "24510") from 1999 to 2008?
## Plotting system: base
# Load data
if(!exists("NEI")) NEI <- readRDS("summarySCC_PM25.rds") # slowwww
if(!exists("SCC")) SCC <- readRDS("Source_Classification_Code.rds")
# ETL (filter & aggregate)
data <- NEI[NEI$fips == "24510",]
aggregated <- aggregate(Emissions ~ year,data=data,FUN=sum)
# Print to screen
barplot(height=aggregated$Emissions/10^3,names.arg=aggregated$year,
xlab="year",ylab="Total PM2.5 Emissions (k Tons)",main="PM2.5 Emissions (k Tons) for Baltimore City")
# Print to png
png("plot2.png", height=480, width=480)
barplot(height=aggregated$Emissions/10^3,names.arg=aggregated$year,
xlab="year",ylab="Total PM2.5 Emissions (k Tons)",main="PM2.5 Emissions (k Tons) for Baltimore City")
dev.off()
## PLOT3
## Question: Of the four types of sources indicated by the type (point, nonpoint, onroad, nonroad) variable, which of these four sources have seen decreases in emissions from 1999–2008 for Baltimore City? Which have seen increases in emissions from 1999–2008?
## Plotting system: ggplot2
# Libraries
library(ggplot2)
# Load data
if(!exists("NEI")) NEI <- readRDS("summarySCC_PM25.rds") # slowwww
if(!exists("SCC")) SCC <- readRDS("Source_Classification_Code.rds")
# ETL
data <- NEI[NEI$fips == "24510",]
aggregated <- aggregate(Emissions ~ year + type,data=data,FUN=sum)
# Print to screen
g <- ggplot(aggregated, aes(year, Emissions, color = type)) + geom_line() + geom_point()
g <- g + labs(x="year",y="Total PM2.5 Emissions (Tons)",title="PM2.5 Emissions for Baltimore by type")
g <- g + theme_bw() + scale_x_continuous(breaks = seq(1999,2008,3))
print(g)
# Print to png
png("plot3.png", height=480, width=480)
g <- ggplot(aggregated, aes(year, Emissions, color = type)) + geom_line() + geom_point()
g <- g + labs(x="year",y="Total PM2.5 Emissions (Tons)",title="PM2.5 Emissions for Baltimore by type")
g <- g + theme_bw() + scale_x_continuous(breaks = seq(1999,2008,3))
print(g)
dev.off()
## PLOT4
## Question: Across the United States, how have emissions from coal combustion-related sources changed from 1999–2008?
## Plotting system: any
# Libraries
library(ggplot2)
library(dplyr)
# Load data
if(!exists("NEI")) NEI <- readRDS("summarySCC_PM25.rds") # slowwww
if(!exists("SCC")) SCC <- readRDS("Source_Classification_Code.rds")
# For speed, first select only coal combustion-related sources in SSC then perform join/merge
coal_related_rows <- grepl("Coal", SCC$Short.Name, ignore.case=TRUE)
SCC_coal <- SCC[coal_related_rows,]
comb_related_rows <- grepl("Comb", SCC$Short.Name, ignore.case=TRUE)
SCC_coal <- SCC[comb_related_rows,]
rm(coal_related_rows,comb_related_rows)
merged <- merge(NEI,SCC_coal[,c("SCC","Short.Name")],by="SCC",all = FALSE)
# Sum up by year
aggregated <- aggregate(Emissions ~ year,data=merged,FUN=sum)
# Print to screen
g <- ggplot(aggregated, aes(year, Emissions)) + geom_area() + geom_point()
g <- g + labs(x="year",y="Total PM2.5 Emissions (Tons)",title="PM2.5 Emissions for coal combustion in Total US")
g <- g + theme_bw() + scale_x_continuous(breaks = seq(1999,2008,3))
print(g)
# Print to png
png("plot4.png", height=480, width=480)
g <- ggplot(aggregated, aes(year, Emissions)) + geom_area() + geom_point()
g <- g + labs(x="year",y="Total PM2.5 Emissions (Tons)",title="PM2.5 Emissions for coal combustion in Total US")
g <- g + theme_bw() + scale_x_continuous(breaks = seq(1999,2008,3))
print(g)
dev.off()
## PLOT5
## Question: How have emissions from motor vehicle sources changed from 1999–2008 in Baltimore City?
## Plotting system: any
# Libraries
library(ggplot2)
library(dplyr)
# Load data
if(!exists("NEI")) NEI <- readRDS("summarySCC_PM25.rds") # slowwww
if(!exists("SCC")) SCC <- readRDS("Source_Classification_Code.rds")
# Select only Baltimore
NEI_Baltimore <- NEI[NEI$fips == "24510",]
# For speed, first select only Vehicle-related sources in SSC then perform join/merge
veh_related_rows <- grepl("Vehicles", SCC$EI.Sector, ignore.case=TRUE)
SCC_veh <- SCC[veh_related_rows,]
rm(veh_related_rows)
merged <- merge(NEI_Baltimore,SCC_veh[,c("SCC","Short.Name")],by="SCC",all = FALSE)
# Sum up by year
aggregated <- aggregate(Emissions ~ year,data=merged,FUN=sum)
# Print to screen
g <- ggplot(aggregated, aes(year, Emissions)) + geom_area() + geom_point()
g <- g + labs(x="year",y="Total PM2.5 Emissions (Tons)",title="PM2.5 Emissions for motor vehicles in Baltimore")
g <- g + theme_bw() + scale_x_continuous(breaks = seq(1999,2008,3))
print(g)
# Print to png
png("plot5.png", height=480, width=480)
g <- ggplot(aggregated, aes(year, Emissions)) + geom_area() + geom_point()
g <- g + labs(x="year",y="Total PM2.5 Emissions (Tons)",title="PM2.5 Emissions for motor vehicles in Baltimore")
g <- g + theme_bw() + scale_x_continuous(breaks = seq(1999,2008,3))
print(g)
dev.off()
## PLOT6
## Question: Compare emissions from motor vehicle sources in Baltimore City with emissions from motor vehicle sources in Los Angeles County, California (fips == "06037"). Which city has seen greater changes over time in motor vehicle emissions?
## Plotting system: any
# Libraries
library(ggplot2)
library(dplyr)
# Load data
if(!exists("NEI")) NEI <- readRDS("summarySCC_PM25.rds") # slowwww
if(!exists("SCC")) SCC <- readRDS("Source_Classification_Code.rds")
# Select only Baltimore
NEI_BaltimoreLA <- NEI[NEI$fips %in% c("24510","06037"),]
# For speed, first select only Vehicle-related sources in SSC then perform join/merge
veh_related_rows <- grepl("Vehicles", SCC$EI.Sector, ignore.case=TRUE)
SCC_veh <- SCC[veh_related_rows,]
rm(veh_related_rows)
merged <- merge(NEI_BaltimoreLA,SCC_veh[,c("SCC","Short.Name")],by="SCC",all = FALSE)
# Sum up by year
aggregated <- aggregate(Emissions ~ year + fips,data=merged,FUN=sum)
# Print to screen
g <- ggplot(aggregated, aes(year, Emissions,color = fips)) + geom_line() + geom_point()
g <- g + labs(x="year",y="Total PM2.5 Emissions (Tons)",title="PM2.5 Emissions for motor vehicles in Baltimore (24510) and LA (06037)")
g <- g + theme_bw() + scale_x_continuous(breaks = seq(1999,2008,3))
print(g)
# Print to png
png("plot6.png", height=480, width=480)
g <- ggplot(aggregated, aes(year, Emissions,color = fips)) + geom_line() + geom_point()
g <- g + labs(x="year",y="Total PM2.5 Emissions (Tons)",title="PM2.5 Emissions for motor vehicles in Baltimore (24510) and LA (06037)")
g <- g + theme_bw() + scale_x_continuous(breaks = seq(1999,2008,3))
print(g)
dev.off()
path.packages("rJava")
path.package("rJava")
library(rJava)
path.package("rJava")
# Set fixed random seed for consistent colors
library(circlize)
# Load data files
Test_purchase_matrix <- read.csv("~/My Box Files/Prestige/Adhoc Analysis/Grey market/Test_purchase_matrix.csv", row.names=1)
mat <- as.matrix(Test_purchase_matrix)
# Set fixed random seed for consistent colors
set.seed(7355608)
# Create chord diagram with no sector labels for now
# col_mat = rand_color(length(mat), transparency = 0.5)
# dim(col_mat) = dim(mat) # to make sure it is a matrix
chordDiagram(mat, directional = TRUE, direction.type = "diffHeight",diffHeight= -0.04,annotationTrack = "grid", preAllocateTracks = list(track.height = 0.3))
# Customize sector labels
circos.trackPlotRegion(track.index = 1, panel.fun = function(x, y) {
xlim = get.cell.meta.data("xlim")
xplot = get.cell.meta.data("xplot")
ylim = get.cell.meta.data("ylim")
sector.name = get.cell.meta.data("sector.index")
# Show country name if >3deg
if(abs(xplot[2] - xplot[1]) > 3) {
circos.text(mean(xlim), ylim[1], sector.name, facing = "clockwise",
niceFacing = TRUE,cex = 0.7, adj = c(0, 0.5))
} else if(abs(xplot[2] - xplot[1]) < 3 && abs(xplot[2] - xplot[1]) > 1) {
circos.text(mean(xlim), ylim[1], sector.name, facing = "clockwise",
niceFacing = TRUE,cex = 0.55, adj = c(0, 0.5))
} else {
circos.text(mean(xlim), ylim[1], sector.name, facing = "clockwise",
niceFacing = TRUE,col = "#00000000", adj = c(0, 0.5))
}
}, bg.border = NA)
ggsave("Network.png",width=5, height=5)
install.packages("ggsave")
source('~/My Box Files/Prestige/Adhoc Analysis/Grey market/chord diagram.R')
?circos
?circlize
?chordDiagram
py <- plotly()
library(plotly)
py <- plotly()
response <- py$plotly(trace0, trace1, kwargs=list(filename="basic-line", fileopt="overwrite"))
objects
objects()
str(Test_purchase_matrix)
summary(Test_purchase_matrix)
x <- 1:4
p <- x/sum(x)
temp <- rbind(x, p)
rownames(temp) <- c("X", "Prob")
temp
x*p
sum(x*p)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
?lm
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
?coef
lm(data=x, weights=w)
mean(x*w)
x*w
mean(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
coef(lm(y ~ x)))
coef(lm(y ~ x))
?lm
coef(lm(y ~ x - 1))
data(mtcars)
colnames(mtcars)
?mtcars
coef(lm(mpg ~ wt))
coef(lm(mpg ~ wt, data=mtcars))
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
(x - mean(x))/std(x)
(x - mean(x))/sd(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
coef(lm(y ~ x))
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
?nls
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
lm(x ~ x)
y<- c(0.573,0.8,0.36,0.44)
x
sum((x-0.573)^2)
sum((x-0.8)^2)
sum((x-0.36)^2)
sum((x-0.44)^2)
file.edit('~/.Rprofile')
sessionInfo()
Give a P-value for the two sided hypothesis test of whether β1 from a linear regression model is 0 or not.
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit<-lm(y ~ x)
summary(fit)
data(mtcars)
?mtcars
fit<-lm(mpg ~ weight,data = mtcars)
fit<-lm(mpg ~ wgt,data = mtcars)
names(mtcars)
fit<-lm(mpg ~ wt,data = mtcars)
summary(fit)
predict(fit,data.frame(x=mean(mtcars$wt)), interval="confidence")
predict(fit,data.frame(x=mean(mtcars$wt)), interval="confidence")
x<-mtcars$wt
y<-mtcars$mpg
fit<-lm(y ~ x)
predict(fit,data.frame(x=mean(x)), interval="confidence")
?mtcars
newdata <- data.frame(x=3000/1000)
p2 <- predict(fit, newdata, interval = ("prediction"))
print(p2)
sum(residuals(fit)^2) / sum((y-mean(y))^2)
?mtcars
?mtcars
setwd("~/My Box Files/DataSciTraining/Repos/StatInf-CourseProject")
newdata <- data.frame(x=3000/1000)
?qplot
?geom_vline
?x_intercept
?geom_vline
?apply
round(((1/.2) / sqrt(40))^2,3)
(1/0.2)^2/40
?replicate
?geom_density
?dnorm
?colours
demo("colors")
?stat_function
library(ggplot2)
x <- seq(0.0,10.0,0.01)
qplot(x,dexp(x,0.2),geom="line",main="Exponential distribution example for lambda = 0.2")
set.seed(123)
nosims <- 1000
n <- 40
lambda <- 0.2
mean_theoretical <- 1/lambda
sd_theoretical <- 1/lambda
# Simulation
means_simulated <- NULL
for (i in 1: nosims) {
means_simulated <- c(means_simulated, mean(rexp(n, lambda)))
}
# Calculate experimental means
mean_experimental <- mean(means_simulated)
# Plot data & means
g <- ggplot() + theme_bw() + ggtitle("Simulated data with expected and experimental means") +
geom_histogram(aes(x=means_simulated),binwidth=0.1) +
geom_vline(xintercept = mean_experimental, colour = "green", size=1.5) +
geom_vline(xintercept = mean_theoretical, colour = "blue", size=1.5)
g
# Calculate expected standard error of the mean squared
SEM2_theoretical <- (sd_theoretical)^2/n
# Calculate true variance
SEM2_experimental <- var(means_simulated)
g2 <- ggplot() + theme_bw() + ggtitle("Simulated data with associated CLT-calculated normal curve") +
geom_histogram(aes(x=means_simulated),binwidth=0.1) +
geom_density(colour = "green") +
stat_function(fun=dnorm, colour="blue",arg=list(mean=mean_theoretical))
g2
g2 <- ggplot() + ggtitle("Simulated data with CLT-calculated normal curve") +
geom_histogram(aes(x=means_simulated),binwidth=0.1)
g2 <- g2 + geom_density(colour = "green") +
stat_function(fun=dnorm, colour="blue",arg=list(mean=mean_theoretical))
g2
g2 <- g2 + geom_density(colour = "green") +
stat_function(fun=dnorm, colour="blue",arg=list(mean=mean_theoretical))
g2
print(g2)
g2 <- g2 + geom_vline(xintercept=5)
g2
